{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78d27f40",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64570899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pathway\n",
      "  Downloading pathway-0.post1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.13.2-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.11-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.8.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.16.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-1.3.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting typing_extensions>=4.5.0 (from sentence-transformers)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting numpy<3.0,>=1.25.0 (from faiss-cpu)\n",
      "  Downloading numpy-2.4.1-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\tahmi\\documents\\work\\hackathons\\iitk_26\\venv\\lib\\site-packages (from faiss-cpu) (25.0)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading pyyaml-6.0.3-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.15-cp312-cp312-win_amd64.whl.metadata (2.3 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.13-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.12-cp312-cp312-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.10-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.2-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.4.2 (from spacy)\n",
      "  Downloading weasel-0.4.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer-slim<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.3-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\tahmi\\documents\\work\\hackathons\\iitk_26\\venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Collecting click>=8.0.0 (from typer-slim<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Downloading cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Downloading smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading markupsafe-3.0.3-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Downloading wrapt-2.0.1-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Downloading pathway-0.post1-py3-none-any.whl (2.8 kB)\n",
      "Downloading sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "Downloading faiss_cpu-1.13.2-cp312-cp312-win_amd64.whl (18.9 MB)\n",
      "   ---------------------------------------- 0.0/18.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/18.9 MB 1.5 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.3/18.9 MB 1.8 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 1.6/18.9 MB 146.9 kB/s eta 0:01:58\n",
      "   --- ------------------------------------ 1.8/18.9 MB 171.8 kB/s eta 0:01:40\n",
      "   ---- ----------------------------------- 2.1/18.9 MB 196.4 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 2.4/18.9 MB 220.8 kB/s eta 0:01:15\n",
      "   ----- ---------------------------------- 2.6/18.9 MB 245.1 kB/s eta 0:01:07\n",
      "   ------ --------------------------------- 2.9/18.9 MB 266.7 kB/s eta 0:01:01\n",
      "   ------ --------------------------------- 2.9/18.9 MB 266.7 kB/s eta 0:01:01\n",
      "   ------ --------------------------------- 2.9/18.9 MB 266.7 kB/s eta 0:01:01\n",
      "   ------ --------------------------------- 2.9/18.9 MB 266.7 kB/s eta 0:01:01\n",
      "   ------ --------------------------------- 2.9/18.9 MB 266.7 kB/s eta 0:01:01\n",
      "   ------ --------------------------------- 2.9/18.9 MB 266.7 kB/s eta 0:01:01\n",
      "   ------ --------------------------------- 2.9/18.9 MB 266.7 kB/s eta 0:01:01\n",
      "   ------ --------------------------------- 2.9/18.9 MB 266.7 kB/s eta 0:01:01\n",
      "   ------ --------------------------------- 2.9/18.9 MB 266.7 kB/s eta 0:01:01\n",
      "   ------ --------------------------------- 2.9/18.9 MB 266.7 kB/s eta 0:01:01\n",
      "   ------ --------------------------------- 2.9/18.9 MB 266.7 kB/s eta 0:01:01\n",
      "   ------ --------------------------------- 2.9/18.9 MB 266.7 kB/s eta 0:01:01\n",
      "   ------ --------------------------------- 3.1/18.9 MB 232.7 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 3.1/18.9 MB 232.7 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 3.1/18.9 MB 232.7 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 3.1/18.9 MB 232.7 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 3.1/18.9 MB 232.7 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 3.1/18.9 MB 232.7 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 3.1/18.9 MB 232.7 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 3.1/18.9 MB 232.7 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 3.1/18.9 MB 232.7 kB/s eta 0:01:08\n",
      "   ------- -------------------------------- 3.4/18.9 MB 219.8 kB/s eta 0:01:11\n",
      "   ------- -------------------------------- 3.4/18.9 MB 219.8 kB/s eta 0:01:11\n",
      "   ------- -------------------------------- 3.4/18.9 MB 219.8 kB/s eta 0:01:11\n",
      "   ------- -------------------------------- 3.4/18.9 MB 219.8 kB/s eta 0:01:11\n",
      "   ------- -------------------------------- 3.4/18.9 MB 219.8 kB/s eta 0:01:11\n",
      "   ------- -------------------------------- 3.4/18.9 MB 219.8 kB/s eta 0:01:11\n",
      "   ------- -------------------------------- 3.4/18.9 MB 219.8 kB/s eta 0:01:11\n",
      "   ------- -------------------------------- 3.4/18.9 MB 219.8 kB/s eta 0:01:11\n",
      "   ------- -------------------------------- 3.4/18.9 MB 219.8 kB/s eta 0:01:11\n",
      "   ------- -------------------------------- 3.4/18.9 MB 219.8 kB/s eta 0:01:11\n",
      "   ------- -------------------------------- 3.4/18.9 MB 219.8 kB/s eta 0:01:11\n",
      "   ------- -------------------------------- 3.7/18.9 MB 205.4 kB/s eta 0:01:15\n",
      "   ------- -------------------------------- 3.7/18.9 MB 205.4 kB/s eta 0:01:15\n",
      "   ------- -------------------------------- 3.7/18.9 MB 205.4 kB/s eta 0:01:15\n",
      "   -------- ------------------------------- 3.9/18.9 MB 213.1 kB/s eta 0:01:11\n",
      "   -------- ------------------------------- 3.9/18.9 MB 213.1 kB/s eta 0:01:11\n",
      "   -------- ------------------------------- 4.2/18.9 MB 223.1 kB/s eta 0:01:06\n",
      "   --------- ------------------------------ 4.5/18.9 MB 233.8 kB/s eta 0:01:02\n",
      "   --------- ------------------------------ 4.5/18.9 MB 233.8 kB/s eta 0:01:02\n",
      "   --------- ------------------------------ 4.7/18.9 MB 244.8 kB/s eta 0:00:58\n",
      "   ---------- ----------------------------- 5.0/18.9 MB 255.7 kB/s eta 0:00:55\n",
      "   ----------- ---------------------------- 5.2/18.9 MB 267.0 kB/s eta 0:00:52\n",
      "   ------------ --------------------------- 5.8/18.9 MB 289.0 kB/s eta 0:00:46\n",
      "   ------------ --------------------------- 6.0/18.9 MB 300.1 kB/s eta 0:00:43\n",
      "   ------------- -------------------------- 6.3/18.9 MB 310.9 kB/s eta 0:00:41\n",
      "   ------------- -------------------------- 6.6/18.9 MB 321.4 kB/s eta 0:00:39\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 6.8/18.9 MB 329.7 kB/s eta 0:00:37\n",
      "   -------------- ------------------------- 7.1/18.9 MB 276.9 kB/s eta 0:00:43\n",
      "   -------------- ------------------------- 7.1/18.9 MB 276.9 kB/s eta 0:00:43\n",
      "   -------------- ------------------------- 7.1/18.9 MB 276.9 kB/s eta 0:00:43\n",
      "   -------------- ------------------------- 7.1/18.9 MB 276.9 kB/s eta 0:00:43\n",
      "   --------------- ------------------------ 7.3/18.9 MB 278.2 kB/s eta 0:00:42\n",
      "   --------------- ------------------------ 7.3/18.9 MB 278.2 kB/s eta 0:00:42\n",
      "   ---------------- ----------------------- 7.6/18.9 MB 283.7 kB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 7.6/18.9 MB 283.7 kB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 7.9/18.9 MB 290.1 kB/s eta 0:00:39\n",
      "   ----------------- ---------------------- 8.1/18.9 MB 157.7 kB/s eta 0:01:09\n",
      "   ----------------- ---------------------- 8.1/18.9 MB 157.7 kB/s eta 0:01:09\n",
      "   ----------------- ---------------------- 8.1/18.9 MB 157.7 kB/s eta 0:01:09\n",
      "   ----------------- ---------------------- 8.1/18.9 MB 157.7 kB/s eta 0:01:09\n",
      "   ----------------- ---------------------- 8.1/18.9 MB 157.7 kB/s eta 0:01:09\n",
      "   ----------------- ---------------------- 8.4/18.9 MB 164.8 kB/s eta 0:01:04\n",
      "   ----------------- ---------------------- 8.4/18.9 MB 164.8 kB/s eta 0:01:04\n",
      "   ------------------ --------------------- 8.7/18.9 MB 171.4 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 8.7/18.9 MB 171.4 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 8.7/18.9 MB 171.4 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 8.7/18.9 MB 171.4 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 8.7/18.9 MB 171.4 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 8.7/18.9 MB 171.4 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 8.7/18.9 MB 171.4 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 8.7/18.9 MB 171.4 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 8.7/18.9 MB 171.4 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 8.7/18.9 MB 171.4 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 8.7/18.9 MB 171.4 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 8.7/18.9 MB 171.4 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 8.7/18.9 MB 171.4 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 8.7/18.9 MB 171.4 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 8.7/18.9 MB 171.4 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 8.7/18.9 MB 171.4 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 8.9/18.9 MB 96.2 kB/s eta 0:01:44\n",
      "   ------------------ --------------------- 8.9/18.9 MB 96.2 kB/s eta 0:01:44\n",
      "   ------------------ --------------------- 8.9/18.9 MB 96.2 kB/s eta 0:01:44\n",
      "   ------------------ --------------------- 8.9/18.9 MB 96.2 kB/s eta 0:01:44\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.2/18.9 MB 82.8 kB/s eta 0:01:58\n",
      "   ------------------- -------------------- 9.4/18.9 MB 86.3 kB/s eta 0:01:50\n",
      "   ------------------- -------------------- 9.4/18.9 MB 86.3 kB/s eta 0:01:50\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   -------------------- ------------------- 9.7/18.9 MB 100.4 kB/s eta 0:01:32\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.0/18.9 MB 91.8 kB/s eta 0:01:38\n",
      "   --------------------- ------------------ 10.2/18.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 10.2/18.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 10.2/18.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 10.2/18.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 10.2/18.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 10.2/18.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 10.2/18.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 10.2/18.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 10.2/18.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 10.2/18.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 10.2/18.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 10.2/18.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 10.2/18.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 10.2/18.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 10.2/18.9 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 10.5/18.9 MB 85.6 kB/s eta 0:01:39\n",
      "   ---------------------- ----------------- 10.5/18.9 MB 85.6 kB/s eta 0:01:39\n",
      "   ---------------------- ----------------- 10.5/18.9 MB 85.6 kB/s eta 0:01:39\n",
      "   ---------------------- ----------------- 10.5/18.9 MB 85.6 kB/s eta 0:01:39\n",
      "   ---------------------- ----------------- 10.5/18.9 MB 85.6 kB/s eta 0:01:39\n",
      "   ---------------------- ----------------- 10.5/18.9 MB 85.6 kB/s eta 0:01:39\n",
      "   ---------------------- ----------------- 10.5/18.9 MB 85.6 kB/s eta 0:01:39\n",
      "   ---------------------- ----------------- 10.5/18.9 MB 85.6 kB/s eta 0:01:39\n",
      "   ---------------------- ----------------- 10.7/18.9 MB 107.2 kB/s eta 0:01:16\n",
      "   ---------------------- ----------------- 10.7/18.9 MB 107.2 kB/s eta 0:01:16\n",
      "   ---------------------- ----------------- 10.7/18.9 MB 107.2 kB/s eta 0:01:16\n",
      "   ----------------------- ---------------- 11.0/18.9 MB 145.9 kB/s eta 0:00:55\n",
      "   ----------------------- ---------------- 11.3/18.9 MB 182.9 kB/s eta 0:00:42\n",
      "   ------------------------ --------------- 11.5/18.9 MB 217.9 kB/s eta 0:00:34\n",
      "   ------------------------ --------------- 11.5/18.9 MB 217.9 kB/s eta 0:00:34\n",
      "   ------------------------ --------------- 11.8/18.9 MB 251.1 kB/s eta 0:00:29\n",
      "   ------------------------- -------------- 12.1/18.9 MB 283.0 kB/s eta 0:00:25\n",
      "   -------------------------- ------------- 12.3/18.9 MB 314.4 kB/s eta 0:00:21\n",
      "   --------------------------- ------------ 12.8/18.9 MB 372.0 kB/s eta 0:00:17\n",
      "   --------------------------- ------------ 13.1/18.9 MB 399.5 kB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 13.4/18.9 MB 426.5 kB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 13.6/18.9 MB 452.5 kB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 14.2/18.9 MB 503.3 kB/s eta 0:00:10\n",
      "   ------------------------------- -------- 14.7/18.9 MB 550.7 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 14.9/18.9 MB 574.2 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 15.5/18.9 MB 620.2 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 16.0/18.9 MB 665.1 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 16.5/18.9 MB 706.4 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 17.0/18.9 MB 748.2 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 17.6/18.9 MB 788.2 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 18.1/18.9 MB 827.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  18.9/18.9 MB 884.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.9/18.9 MB 880.5 kB/s eta 0:00:00\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.0 MB 2.8 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.0/12.0 MB 3.1 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.8/12.0 MB 3.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.4/12.0 MB 3.1 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.1/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.7/12.0 MB 635.8 kB/s eta 0:00:14\n",
      "   ------------- -------------------------- 4.2/12.0 MB 697.1 kB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 5.0/12.0 MB 801.0 kB/s eta 0:00:09\n",
      "   -------------------- ------------------- 6.0/12.0 MB 941.6 kB/s eta 0:00:07\n",
      "   ------------------------ --------------- 7.3/12.0 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 8.9/12.0 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 11.0/12.0 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 1.7 MB/s eta 0:00:00\n",
      "Downloading torch-2.9.1-cp312-cp312-win_amd64.whl (110.9 MB)\n",
      "   ---------------------------------------- 0.0/110.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 2.9/110.9 MB 13.9 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 7.1/110.9 MB 16.7 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 12.8/110.9 MB 20.1 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 19.9/110.9 MB 23.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 28.8/110.9 MB 27.3 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 39.3/110.9 MB 31.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 40.1/110.9 MB 29.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 42.2/110.9 MB 26.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 42.5/110.9 MB 23.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 43.0/110.9 MB 20.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 43.3/110.9 MB 19.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 43.5/110.9 MB 18.1 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 43.5/110.9 MB 18.1 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 43.8/110.9 MB 16.0 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 43.8/110.9 MB 16.0 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 44.0/110.9 MB 13.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 44.0/110.9 MB 13.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 44.0/110.9 MB 13.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 44.0/110.9 MB 13.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 44.0/110.9 MB 13.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 44.0/110.9 MB 13.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 44.0/110.9 MB 13.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 44.0/110.9 MB 13.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 44.0/110.9 MB 13.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 44.0/110.9 MB 13.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 44.0/110.9 MB 13.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 44.3/110.9 MB 8.1 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 44.3/110.9 MB 8.1 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 44.6/110.9 MB 7.4 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 44.6/110.9 MB 7.4 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 44.8/110.9 MB 7.1 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 45.1/110.9 MB 6.8 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 45.1/110.9 MB 6.8 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 45.1/110.9 MB 6.8 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 45.4/110.9 MB 6.3 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 45.4/110.9 MB 6.3 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 45.6/110.9 MB 6.0 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 45.9/110.9 MB 5.8 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 45.9/110.9 MB 5.8 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 46.1/110.9 MB 5.6 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 46.4/110.9 MB 5.5 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 46.7/110.9 MB 5.4 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 46.9/110.9 MB 5.3 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 47.4/110.9 MB 5.1 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 47.7/110.9 MB 5.1 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 48.0/110.9 MB 5.0 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 48.5/110.9 MB 4.9 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 48.8/110.9 MB 4.9 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 49.3/110.9 MB 4.8 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 49.8/110.9 MB 4.8 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 50.3/110.9 MB 4.7 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 50.6/110.9 MB 4.7 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 51.1/110.9 MB 4.6 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 51.6/110.9 MB 4.6 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 52.4/110.9 MB 4.5 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 53.0/110.9 MB 4.5 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 53.5/110.9 MB 4.5 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 54.3/110.9 MB 4.5 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 54.8/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 55.6/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 56.1/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 56.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.7/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.9/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 58.2/110.9 MB 3.5 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 58.2/110.9 MB 3.5 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 58.2/110.9 MB 3.5 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 58.2/110.9 MB 3.5 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.5/110.9 MB 3.3 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 58.7/110.9 MB 2.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 58.7/110.9 MB 2.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 58.7/110.9 MB 2.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 58.7/110.9 MB 2.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 58.7/110.9 MB 2.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 58.7/110.9 MB 2.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 58.7/110.9 MB 2.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 58.7/110.9 MB 2.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 58.7/110.9 MB 2.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 58.7/110.9 MB 2.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 58.7/110.9 MB 2.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 58.7/110.9 MB 2.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 58.7/110.9 MB 2.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 58.7/110.9 MB 2.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 59.0/110.9 MB 2.4 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 59.0/110.9 MB 2.4 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 59.2/110.9 MB 2.4 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 59.5/110.9 MB 2.3 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 59.5/110.9 MB 2.3 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 60.0/110.9 MB 2.3 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 60.3/110.9 MB 2.3 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 61.1/110.9 MB 2.3 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 61.6/110.9 MB 2.3 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 62.4/110.9 MB 2.3 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 63.7/110.9 MB 2.4 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 65.3/110.9 MB 2.4 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 67.1/110.9 MB 2.5 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 69.7/110.9 MB 2.5 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 72.9/110.9 MB 2.6 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 77.6/110.9 MB 2.8 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 82.6/110.9 MB 2.9 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 86.5/110.9 MB 3.1 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 91.2/110.9 MB 3.2 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 94.1/110.9 MB 3.3 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 95.7/110.9 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 97.3/110.9 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 98.8/110.9 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 100.4/110.9 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 102.0/110.9 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 103.5/110.9 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 104.3/110.9 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 105.6/110.9 MB 3.3 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 106.7/110.9 MB 3.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 108.0/110.9 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.1/110.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.4/110.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.9/110.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 110.9/110.9 MB 2.4 MB/s eta 0:00:00\n",
      "Using cached spacy-3.8.11-cp312-cp312-win_amd64.whl (14.2 MB)\n",
      "Using cached scikit_learn-1.8.0-cp312-cp312-win_amd64.whl (8.0 MB)\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.13-cp312-cp312-win_amd64.whl (40 kB)\n",
      "Downloading fsspec-2026.1.0-py3-none-any.whl (201 kB)\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.1/566.1 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Using cached murmurhash-1.0.15-cp312-cp312-win_amd64.whl (25 kB)\n",
      "Using cached networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "Downloading numpy-2.4.1-cp312-cp312-win_amd64.whl (12.3 MB)\n",
      "   ---------------------------------------- 0.0/12.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/12.3 MB 6.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.4/12.3 MB 6.1 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.7/12.3 MB 6.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.0/12.3 MB 6.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.3/12.3 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.6/12.3 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.2/12.3 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.2/12.3 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.0/12.3 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.3/12.3 MB 5.8 MB/s eta 0:00:00\n",
      "Using cached preshed-3.0.12-cp312-cp312-win_amd64.whl (118 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_core-2.41.5-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl (154 kB)\n",
      "Using cached regex-2025.11.3-cp312-cp312-win_amd64.whl (277 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Downloading scipy-1.16.3-cp312-cp312-win_amd64.whl (38.6 MB)\n",
      "   ---------------------------------------- 0.0/38.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/38.6 MB 5.6 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.4/38.6 MB 5.6 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.4/38.6 MB 5.6 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 4.7/38.6 MB 5.6 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 6.0/38.6 MB 5.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 7.3/38.6 MB 5.7 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 8.7/38.6 MB 5.8 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 10.0/38.6 MB 5.9 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 11.3/38.6 MB 6.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 12.6/38.6 MB 6.0 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 14.2/38.6 MB 6.0 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 15.5/38.6 MB 6.1 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 17.0/38.6 MB 6.2 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 18.4/38.6 MB 6.2 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 19.7/38.6 MB 6.2 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 20.7/38.6 MB 6.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 21.0/38.6 MB 5.9 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 21.8/38.6 MB 5.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 22.3/38.6 MB 5.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 23.1/38.6 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 23.9/38.6 MB 5.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 24.6/38.6 MB 5.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 25.4/38.6 MB 5.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 26.2/38.6 MB 5.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 27.0/38.6 MB 5.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 27.8/38.6 MB 5.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 28.6/38.6 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.6/38.6 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.4/38.6 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.5/38.6 MB 5.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.5/38.6 MB 5.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.3/38.6 MB 5.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.3/38.6 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.4/38.6 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.4/38.6 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.5/38.6 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.6/38.6 MB 4.9 MB/s eta 0:00:00\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.5.2-cp312-cp312-win_amd64.whl (654 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached thinc-8.3.10-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tokenizers-0.22.2-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.3-py3-none-any.whl (50 kB)\n",
      "Using cached filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached blis-1.3.3-cp312-cp312-win_amd64.whl (6.2 MB)\n",
      "Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Using cached cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Using cached wrapt-2.0.1-cp312-cp312-win_amd64.whl (60 kB)\n",
      "Installing collected packages: mpmath, wrapt, wasabi, urllib3, typing_extensions, tqdm, threadpoolctl, sympy, spacy-loggers, spacy-legacy, setuptools, safetensors, regex, pyyaml, pathway, numpy, networkx, murmurhash, MarkupSafe, joblib, idna, fsspec, filelock, cymem, cloudpathlib, click, charset_normalizer, certifi, catalogue, annotated-types, typing-inspection, typer-slim, srsly, smart-open, scipy, requests, pydantic-core, preshed, jinja2, faiss-cpu, blis, torch, scikit-learn, pydantic, huggingface-hub, tokenizers, confection, weasel, transformers, thinc, spacy, sentence-transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'c:\\\\Users\\\\tahmi\\\\Documents\\\\Work\\\\HACKATHONS\\\\iitk_26\\\\venv\\\\Lib\\\\site-packages\\\\mpmath\\\\tests\\\\test_power.py'\n",
      "Check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pathway\n",
      "  Using cached pathway-0.post1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.13.2-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.9.1-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.8.11-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.8.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.16.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-1.3.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting typing_extensions>=4.5.0 (from sentence-transformers)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting numpy<3.0,>=1.25.0 (from faiss-cpu)\n",
      "  Using cached numpy-2.4.1-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\tahmi\\documents\\work\\hackathons\\iitk_26\\venv\\lib\\site-packages (from faiss-cpu) (25.0)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2025.11.3-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Using cached tokenizers-0.22.2-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Using cached networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Using cached fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Using cached murmurhash-1.0.15-cp312-cp312-win_amd64.whl.metadata (2.3 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Using cached cymem-2.0.13-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Using cached preshed-3.0.12-cp312-cp312-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Using cached thinc-8.3.10-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Using cached srsly-2.5.2-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.4.2 (from spacy)\n",
      "  Using cached weasel-0.4.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer-slim<1.0.0,>=0.3.0 (from spacy)\n",
      "  Using cached typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached pydantic_core-2.41.5-cp312-cp312-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
      "  Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached blis-1.3.3-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\tahmi\\documents\\work\\hackathons\\iitk_26\\venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Collecting click>=8.0.0 (from typer-slim<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Using cached cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Using cached smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Using cached wrapt-2.0.1-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Using cached pathway-0.post1-py3-none-any.whl (2.8 kB)\n",
      "Using cached sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "Using cached faiss_cpu-1.13.2-cp312-cp312-win_amd64.whl (18.9 MB)\n",
      "Using cached transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "Downloading torch-2.9.1-cp312-cp312-win_amd64.whl (110.9 MB)\n",
      "   ---------------------------------------- 0.0/110.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/110.9 MB 8.5 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 10.5/110.9 MB 36.4 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 26.5/110.9 MB 54.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 43.3/110.9 MB 62.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 60.0/110.9 MB 67.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 71.8/110.9 MB 65.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 84.7/110.9 MB 64.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 97.8/110.9 MB 63.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 107.2/110.9 MB 61.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  110.9/110.9 MB 60.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 110.9/110.9 MB 55.3 MB/s eta 0:00:00\n",
      "Downloading spacy-3.8.11-cp312-cp312-win_amd64.whl (14.2 MB)\n",
      "   ---------------------------------------- 0.0/14.2 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 6.6/14.2 MB 33.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.6/14.2 MB 32.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.2/14.2 MB 30.8 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.8.0-cp312-cp312-win_amd64.whl (8.0 MB)\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 5.2/8.0 MB 31.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.3/8.0 MB 21.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.0/8.0 MB 13.8 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cymem-2.0.13-cp312-cp312-win_amd64.whl (40 kB)\n",
      "Downloading fsspec-2026.1.0-py3-none-any.whl (201 kB)\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.1/566.1 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading murmurhash-1.0.15-cp312-cp312-win_amd64.whl (25 kB)\n",
      "Downloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 23.2 MB/s eta 0:00:00\n",
      "Downloading numpy-2.4.1-cp312-cp312-win_amd64.whl (12.3 MB)\n",
      "   ---------------------------------------- 0.0/12.3 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 5.0/12.3 MB 25.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.0/12.3 MB 24.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.3/12.3 MB 24.1 MB/s eta 0:00:00\n",
      "Downloading preshed-3.0.12-cp312-cp312-win_amd64.whl (118 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 18.7 MB/s eta 0:00:00\n",
      "Downloading pyyaml-6.0.3-cp312-cp312-win_amd64.whl (154 kB)\n",
      "Downloading regex-2025.11.3-cp312-cp312-win_amd64.whl (277 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Downloading scipy-1.16.3-cp312-cp312-win_amd64.whl (38.6 MB)\n",
      "   ---------------------------------------- 0.0/38.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.4/38.6 MB 16.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 7.3/38.6 MB 17.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 11.5/38.6 MB 17.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 15.5/38.6 MB 18.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 19.7/38.6 MB 18.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.9/38.6 MB 18.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 28.3/38.6 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.5/38.6 MB 18.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.7/38.6 MB 19.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.6/38.6 MB 18.4 MB/s eta 0:00:00\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.2-cp312-cp312-win_amd64.whl (654 kB)\n",
      "   ---------------------------------------- 0.0/654.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 654.8/654.8 kB 26.2 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 4.2/6.3 MB 21.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 20.3 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.10-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 18.7 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 17.8 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.3-py3-none-any.whl (50 kB)\n",
      "Downloading filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 14.9 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading blis-1.3.3-cp312-cp312-win_amd64.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 20.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 18.9 MB/s eta 0:00:00\n",
      "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading markupsafe-3.0.3-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 17.1 MB/s eta 0:00:00\n",
      "Downloading smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Downloading wrapt-2.0.1-cp312-cp312-win_amd64.whl (60 kB)\n",
      "Installing collected packages: mpmath, wrapt, wasabi, urllib3, typing_extensions, tqdm, threadpoolctl, sympy, spacy-loggers, spacy-legacy, setuptools, safetensors, regex, pyyaml, pathway, numpy, networkx, murmurhash, MarkupSafe, joblib, idna, fsspec, filelock, cymem, cloudpathlib, click, charset_normalizer, certifi, catalogue, annotated-types, typing-inspection, typer-slim, srsly, smart-open, scipy, requests, pydantic-core, preshed, jinja2, faiss-cpu, blis, torch, scikit-learn, pydantic, huggingface-hub, tokenizers, confection, weasel, transformers, thinc, spacy, sentence-transformers\n",
      "Successfully installed MarkupSafe-3.0.3 annotated-types-0.7.0 blis-1.3.3 catalogue-2.0.10 certifi-2026.1.4 charset_normalizer-3.4.4 click-8.3.1 cloudpathlib-0.23.0 confection-0.1.5 cymem-2.0.13 faiss-cpu-1.13.2 filelock-3.20.3 fsspec-2026.1.0 huggingface-hub-0.36.0 idna-3.11 jinja2-3.1.6 joblib-1.5.3 mpmath-1.3.0 murmurhash-1.0.15 networkx-3.6.1 numpy-2.4.1 pathway-0.post1 preshed-3.0.12 pydantic-2.12.5 pydantic-core-2.41.5 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 scikit-learn-1.8.0 scipy-1.16.3 sentence-transformers-5.2.0 setuptools-80.9.0 smart-open-7.5.0 spacy-3.8.11 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.2 sympy-1.14.0 thinc-8.3.10 threadpoolctl-3.6.0 tokenizers-0.22.2 torch-2.9.1 tqdm-4.67.1 transformers-4.57.3 typer-slim-0.21.1 typing-inspection-0.4.2 typing_extensions-4.15.0 urllib3-2.6.3 wasabi-1.1.3 weasel-0.4.3 wrapt-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install pathway sentence-transformers faiss-cpu transformers torch spacy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f58599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting allennlp\n",
      "  Downloading allennlp-2.10.1-py3-none-any.whl.metadata (21 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 98, in read\n",
      "    data: bytes = self.__fp.read(amt)\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py\", line 479, in read\n",
      "    s = self.fp.read(amt)\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\socket.py\", line 720, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py\", line 1251, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py\", line 1103, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 386, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 95, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "                            ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 546, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 397, in resolve\n",
      "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 173, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 156, in __bool__\n",
      "    return bool(self._sequence)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 174, in __bool__\n",
      "    return any(self)\n",
      "           ^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 162, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "                       ^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 53, in _iter_built\n",
      "    candidate = func()\n",
      "                ^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 187, in _make_candidate_from_link\n",
      "    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 233, in _make_base_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "                                       ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 304, in __init__\n",
      "    super().__init__(\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 159, in __init__\n",
      "    self.dist = self._prepare()\n",
      "                ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 236, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 315, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 521, in prepare_linked_requirement\n",
      "    metadata_dist = self._fetch_metadata_only(req)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 373, in _fetch_metadata_only\n",
      "    return self._fetch_metadata_using_link_data_attr(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 393, in _fetch_metadata_using_link_data_attr\n",
      "    metadata_file = get_http_url(\n",
      "                    ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 111, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\network\\download.py\", line 148, in __call__\n",
      "    for chunk in chunks:\n",
      "                 ^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 65, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 560, in read\n",
      "    with self._error_catcher():\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    }
   ],
   "source": [
    "# pip install allennlp allennlp-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1acf681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%python` not found (But cell magic `%%python` exists, did you mean that instead?).\n"
     ]
    }
   ],
   "source": [
    "# python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c7f603",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e37422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "import json\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict, Counter\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from ftfy import fix_text\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb94f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tahmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b0d6f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "embedder = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "nli = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"roberta-large-mnli\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b32c7bf",
   "metadata": {},
   "source": [
    "# Load Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "509df933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded books: ['In search of the castaways.txt', 'the count of monte cristo.txt']\n"
     ]
    }
   ],
   "source": [
    "BOOK_DIR = \"Books\"\n",
    "\n",
    "books = {}\n",
    "for fname in os.listdir(BOOK_DIR):\n",
    "    if fname.endswith(\".txt\"):\n",
    "        with open(os.path.join(BOOK_DIR, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "            books[fname] = f.read()\n",
    "\n",
    "print(\"Loaded books:\", list(books.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f746121",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbde7f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def chunk_text(\n",
    "    text: str,\n",
    "    max_chars: int = 3500,\n",
    "    overlap_sents: int = 2\n",
    "):\n",
    "    \"\"\"\n",
    "    Sentence-aware chunking for long narrative text.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "\n",
    "    current = []\n",
    "    current_len = 0\n",
    "\n",
    "    for sent in sentences:\n",
    "        sent_len = len(sent)\n",
    "\n",
    "        # if adding sentence exceeds limit > flush\n",
    "        if current and current_len + sent_len > max_chars:\n",
    "            chunks.append(\" \".join(current))\n",
    "\n",
    "            # sentence-level overlap\n",
    "            current = current[-overlap_sents:] if overlap_sents > 0 else []\n",
    "            current_len = sum(len(s) for s in current)\n",
    "\n",
    "        current.append(sent)\n",
    "        current_len += sent_len\n",
    "\n",
    "    if current:\n",
    "        chunks.append(\" \".join(current))\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd46625",
   "metadata": {},
   "source": [
    "## Preprocess Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d84df6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preprocessing books (chunking + embedding)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|| 8/8 [01:36<00:00, 12.09s/it]\n",
      "Batches: 100%|| 28/28 [05:07<00:00, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preprocessed data saved to cache.\n",
      "\n",
      "Chunks per book:\n",
      "In search of the castaways.txt: 251\n",
      "the count of monte cristo.txt: 881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "CACHE_DIR = \"cache/v2\"\n",
    "CHUNKS_PATH = os.path.join(CACHE_DIR, \"book_chunks.pkl\")\n",
    "EMB_PATH = os.path.join(CACHE_DIR, \"book_embeddings.pkl\")\n",
    "\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_pickle(obj, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def normalize_embeddings(E):\n",
    "    norms = np.linalg.norm(E, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1.0\n",
    "    return E / norms\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "\n",
    "if os.path.exists(CHUNKS_PATH) and os.path.exists(EMB_PATH):\n",
    "    print(\"==> Loading preprocessed books from cache...\")\n",
    "    book_chunks = load_pickle(CHUNKS_PATH)\n",
    "    book_embeddings = load_pickle(EMB_PATH)\n",
    "\n",
    "# -----------------------------------------\n",
    "\n",
    "else:\n",
    "    print(\"==> Preprocessing books (chunking + embedding)...\")\n",
    "\n",
    "    book_chunks = {}\n",
    "    book_embeddings = {}\n",
    "\n",
    "    for book_name, text in books.items():\n",
    "        chunks = chunk_text(text)\n",
    "\n",
    "        embeddings = embedder.encode(\n",
    "            chunks,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "\n",
    "        book_chunks[book_name] = chunks\n",
    "        book_embeddings[book_name] = embeddings\n",
    "\n",
    "    save_pickle(book_chunks, CHUNKS_PATH)\n",
    "    save_pickle(book_embeddings, EMB_PATH)\n",
    "\n",
    "    print(\"==> Preprocessed data saved to cache.\")\n",
    "\n",
    "# ------------------\n",
    "\n",
    "print(\"\\nChunks per book:\")\n",
    "for k in sorted(book_chunks):\n",
    "    print(f\"{k}: {len(book_chunks[k])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0696833",
   "metadata": {},
   "source": [
    "# Decompose Backstory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d8ebd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PATH = \"data/raw/train.csv\"\n",
    "OUT_DIR = \"data2/decomposed\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(RAW_PATH)\n",
    "\n",
    "_ws_re = re.compile(r\"\\s+\")\n",
    "\n",
    "def clean_text(t):\n",
    "    if pd.isna(t):\n",
    "        return \"\"\n",
    "\n",
    "    t = fix_text(str(t))          \n",
    "    t = _ws_re.sub(\" \", t)\n",
    "    return t.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ea81e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clauses(sent, char):\n",
    "    clauses = []\n",
    "\n",
    "    root = sent.root\n",
    "\n",
    "    # main clause\n",
    "    clauses.append(sent.text)\n",
    "\n",
    "    # coordinated verbs > separate events\n",
    "    for tok in sent:\n",
    "        if tok.dep_ == \"conj\" and tok.head == root:\n",
    "            span = sent.doc[tok.left_edge.i : tok.right_edge.i + 1]\n",
    "            clauses.append(span.text)\n",
    "\n",
    "    # adverbial / temporal clauses\n",
    "    for tok in sent:\n",
    "        if tok.dep_ in (\"advcl\", \"relcl\"):\n",
    "            span = sent.doc[tok.left_edge.i : tok.right_edge.i + 1]\n",
    "            clauses.append(span.text)\n",
    "\n",
    "    cleaned = []\n",
    "    for c in clauses:\n",
    "        c = c.strip()\n",
    "        if len(c) < 20:\n",
    "            continue\n",
    "\n",
    "        # ensure explicit subject\n",
    "        if char.lower() not in c.lower():\n",
    "            c = f\"{char} {c}\"\n",
    "\n",
    "        cleaned.append(c)\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def decompose_backstory(row):\n",
    "    claims = []\n",
    "\n",
    "    text = clean_text(row[\"content\"])\n",
    "    char = row[\"char\"]\n",
    "\n",
    "    if not text:\n",
    "        return claims\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        sent_clauses = extract_clauses(sent, char)\n",
    "        claims.extend(sent_clauses)\n",
    "\n",
    "    # deduplicate softly\n",
    "    seen = set()\n",
    "    final_claims = []\n",
    "    for c in claims:\n",
    "        key = c.lower()\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            final_claims.append(c)\n",
    "\n",
    "    return final_claims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0ed22d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 204 atomic claims.\n"
     ]
    }
   ],
   "source": [
    "claims_out = []\n",
    "index_out = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    claims = decompose_backstory(row)\n",
    "\n",
    "    for i, claim in enumerate(claims):\n",
    "        cid = f\"{row['id']}_{i}\"\n",
    "\n",
    "        claims_out.append({\n",
    "            \"claim_id\": cid,\n",
    "            \"row_id\": int(row[\"id\"]),\n",
    "            \"book_name\": row[\"book_name\"],\n",
    "            \"character\": row[\"char\"],\n",
    "            \"claim_text\": claim,\n",
    "            \"source\": \"content\",\n",
    "            \"label\": row[\"label\"]\n",
    "        })\n",
    "\n",
    "        index_out.append({\n",
    "            \"claim_id\": cid,\n",
    "            \"row_id\": int(row[\"id\"])\n",
    "        })\n",
    "\n",
    "with open(f\"{OUT_DIR}/claims.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for c in claims_out:\n",
    "        f.write(json.dumps(c, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "with open(f\"{OUT_DIR}/index.json\", \"w\") as f:\n",
    "    json.dump(index_out, f, indent=2)\n",
    "\n",
    "print(f\"Saved {len(claims_out)} atomic claims.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7fcbf4",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "\n",
    "\n",
    "\n",
    "Claim >Claim embedding > ANN / cosine top-K (fast, coarse) > MMR rerank (diversity-aware)> Optional sentence-level refinement > Evidence pack (with scores + offsets)\n",
    "\n",
    "\n",
    "\n",
    "MMR(d) =   sim(q, d)  (1  )  max sim(d, d_selected)\n",
    "\n",
    "  0.60.8 (relevance vs diversity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a095fa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading claims...\n",
      "Loading book chunks...\n",
      "Loading book embeddings...\n",
      "\n",
      "Validating book alignment...\n",
      "==> Book alignment OK\n",
      "Embedding dim: 768\n",
      "\n",
      "Retrieving evidence...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 204/204 [00:11<00:00, 18.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Done. Wrote evidence for 204 claims.\n",
      "Output saved to: data2/retrieval/claim_evidence.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CLAIMS_PATH = \"data2/decomposed/claims.jsonl\"\n",
    "BOOK_CHUNKS_PATH = \"data2/books/book_chunks.pkl\"\n",
    "BOOK_EMBEDS_PATH = \"data2/books/book_embeddings.pkl\"\n",
    "\n",
    "OUT_DIR = \"data2/retrieval\"\n",
    "OUT_PATH = f\"{OUT_DIR}/claim_evidence.jsonl\"\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# --------------\n",
    "\n",
    "def normalize_book_name(name: str) -> str:\n",
    "    return re.sub(r\"\\.txt$\", \"\", name.lower().strip())\n",
    "\n",
    "\n",
    "def normalize_embeddings(E: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"L2-normalize embeddings row-wise.\"\"\"\n",
    "    norms = np.linalg.norm(E, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1.0\n",
    "    return E / norms\n",
    "\n",
    "# -------------------------------\n",
    "\n",
    "print(\"Loading claims...\")\n",
    "claims = [json.loads(l) for l in open(CLAIMS_PATH, encoding=\"utf-8\")]\n",
    "assert claims, \"claims.jsonl is empty\"\n",
    "\n",
    "\n",
    "print(\"Loading book chunks...\")\n",
    "with open(BOOK_CHUNKS_PATH, \"rb\") as f:\n",
    "    raw_chunks = pickle.load(f)\n",
    "\n",
    "print(\"Loading book embeddings...\")\n",
    "with open(BOOK_EMBEDS_PATH, \"rb\") as f:\n",
    "    raw_embeddings = pickle.load(f)\n",
    "\n",
    "\n",
    "book_chunks: Dict[str, List[str]] = {\n",
    "    normalize_book_name(k): v\n",
    "    for k, v in raw_chunks.items()\n",
    "}\n",
    "\n",
    "book_embeddings: Dict[str, np.ndarray] = {\n",
    "    normalize_book_name(k): normalize_embeddings(v)\n",
    "    for k, v in raw_embeddings.items()\n",
    "}\n",
    "\n",
    "\n",
    "# -------------------\n",
    "\n",
    "print(\"\\nValidating book alignment...\")\n",
    "for k in book_chunks:\n",
    "    assert k in book_embeddings, f\"Missing embeddings for book: {k}\"\n",
    "    assert len(book_chunks[k]) == book_embeddings[k].shape[0], \\\n",
    "        f\"Chunk/embedding mismatch in {k}\"\n",
    "\n",
    "missing_books = {\n",
    "    c[\"book_name\"]\n",
    "    for c in claims\n",
    "    if normalize_book_name(c[\"book_name\"]) not in book_embeddings\n",
    "}\n",
    "assert not missing_books, f\"Claims reference missing books: {missing_books}\"\n",
    "\n",
    "print(\"==> Book alignment OK\")\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "\n",
    "embedder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "print(\"Embedding dim:\", next(iter(book_embeddings.values())).shape[1])\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "\n",
    "def topk_cosine(query_emb: np.ndarray,\n",
    "                doc_embs: np.ndarray,\n",
    "                k: int = 50):\n",
    "    \n",
    "    sims = doc_embs @ query_emb\n",
    "    k = min(k, len(sims))\n",
    "    top_ids = np.argpartition(-sims, k - 1)[:k]\n",
    "    return top_ids, sims\n",
    "\n",
    "\n",
    "def mmr(query_emb: np.ndarray,\n",
    "        doc_embs: np.ndarray,\n",
    "        top_k: int = 5,\n",
    "        lambda_param: float = 0.7):\n",
    "    \"\"\"\n",
    "    Maximal Marginal Relevance over a small candidate set.\n",
    "    \"\"\"\n",
    "    sim_q = doc_embs @ query_emb\n",
    "    sim_dd = doc_embs @ doc_embs.T\n",
    "\n",
    "    selected = []\n",
    "    candidates = set(range(len(doc_embs)))\n",
    "\n",
    "    for _ in range(min(top_k, len(candidates))):\n",
    "        best_idx, best_score = None, -1e9\n",
    "\n",
    "        for i in candidates:\n",
    "            diversity = max(sim_dd[i][j] for j in selected) if selected else 0.0\n",
    "            score = lambda_param * sim_q[i] - (1 - lambda_param) * diversity\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_idx = i\n",
    "\n",
    "        selected.append(best_idx)\n",
    "        candidates.remove(best_idx)\n",
    "\n",
    "    return selected\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "\n",
    "print(\"\\nRetrieving evidence...\")\n",
    "\n",
    "written = 0\n",
    "\n",
    "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as fout:\n",
    "    for claim in tqdm(claims):\n",
    "        book = normalize_book_name(claim[\"book_name\"])\n",
    "\n",
    "        chunks = book_chunks[book]\n",
    "        embeds = book_embeddings[book]\n",
    "\n",
    "        # Encode claim\n",
    "        q_emb = embedder.encode(\n",
    "            claim[\"claim_text\"],\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True\n",
    "        )\n",
    "\n",
    "        # ---------- Coarse retrieval ----------\n",
    "        top_ids, sims = topk_cosine(\n",
    "            q_emb,\n",
    "            embeds,\n",
    "            k=50\n",
    "        )\n",
    "\n",
    "        # ---------- MMR reranking ----------\n",
    "        mmr_local_ids = mmr(\n",
    "            q_emb,\n",
    "            embeds[top_ids],\n",
    "            top_k=5,\n",
    "            lambda_param=0.7\n",
    "        )\n",
    "\n",
    "        selected_ids = [top_ids[i] for i in mmr_local_ids]\n",
    "\n",
    "        # ---------- Evidence pack ----------\n",
    "        evidence = [{\n",
    "            \"chunk_id\": int(idx),\n",
    "            \"text\": chunks[idx],\n",
    "            \"similarity\": float(embeds[idx] @ q_emb)\n",
    "        } for idx in selected_ids]\n",
    "\n",
    "        fout.write(json.dumps({\n",
    "            \"claim_id\": claim[\"claim_id\"],\n",
    "            \"row_id\": claim[\"row_id\"],\n",
    "            \"book_name\": claim[\"book_name\"],\n",
    "            \"character\": claim[\"character\"],\n",
    "            \"claim_text\": claim[\"claim_text\"],\n",
    "            \"label\": claim[\"label\"],\n",
    "            \"evidence\": evidence\n",
    "        }, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "        written += 1\n",
    "\n",
    "\n",
    "assert written > 0, \"No evidence written  pipeline failure\"\n",
    "\n",
    "print(f\"\\n==> Done. Wrote evidence for {written} claims.\")\n",
    "print(f\"Output saved to: {OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14044e66",
   "metadata": {},
   "source": [
    "# NLI CLassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2143f847",
   "metadata": {},
   "source": [
    "### Generate weak NLI Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87a1de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "IN_PATH = \"data2/retrieval/claim_evidence.jsonl\"\n",
    "OUT_DIR = \"data2/nli\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "STOPWORDS = {\n",
    "    # Articles\n",
    "    \"the\", \"a\", \"an\",\n",
    "\n",
    "    # Conjunctions (safe)\n",
    "    \"and\", \"or\", \"but\",\n",
    "\n",
    "    # Prepositions (high-frequency, low semantic load)\n",
    "    \"to\", \"of\", \"in\", \"on\", \"for\", \"with\", \"as\", \"by\", \"at\", \"from\",\n",
    "    \"into\", \"onto\", \"upon\", \"within\", \"without\", \"between\", \"among\",\n",
    "\n",
    "    # Copula / light verbs (safe only in lemma form)\n",
    "    \"be\", \"was\", \"were\", \"is\", \"are\", \"been\", \"being\",\n",
    "\n",
    "    # Dialogue & discourse fillers\n",
    "    \"said\", \"say\", \"told\", \"tell\", \"asked\", \"ask\",\n",
    "    \"replied\", \"reply\", \"answered\", \"answer\",\n",
    "    \"then\", \"there\", \"here\", \"now\",\n",
    "\n",
    "    # Pronouns (subject/object noise)\n",
    "    \"he\", \"she\", \"they\", \"them\", \"him\", \"her\",\n",
    "    \"it\", \"its\", \"their\", \"his\", \"hers\",\n",
    "\n",
    "    # Quantifiers / determiners\n",
    "    \"some\", \"any\", \"each\", \"every\", \"many\", \"much\", \"few\",\n",
    "\n",
    "    # Intensifiers (usually not event-bearing)\n",
    "    \"very\", \"quite\", \"rather\", \"too\", \"so\"\n",
    "}\n",
    "\n",
    "TOKEN_RE = re.compile(r\"[a-z]+(?:'[a-z]+)?\")\n",
    "\n",
    "\n",
    "EXPLICIT_NEG = {\n",
    "    \"not\", \"never\", \"no\", \"none\", \"nothing\", \"nobody\", \"nowhere\",\n",
    "    \"neither\", \"nor\", \"without\"\n",
    "}\n",
    "\n",
    "AUX_NEG = {\n",
    "    \"didn't\", \"doesn't\", \"don't\",\n",
    "    \"wasn't\", \"weren't\", \"isn't\", \"aren't\",\n",
    "    \"haven't\", \"hasn't\", \"hadn't\",\n",
    "    \"won't\", \"wouldn't\", \"couldn't\", \"shouldn't\", \"can't\"\n",
    "}\n",
    "\n",
    "IMPLICIT_NEG_VERBS = {\n",
    "    \"fail\", \"refuse\", \"deny\", \"avoid\", \"prevent\",\n",
    "    \"stop\", \"forbid\", \"miss\", \"lack\", \"lose\"\n",
    "}\n",
    "\n",
    "WEAK_NEG_ADVERBS = {\n",
    "    \"hardly\", \"barely\", \"scarcely\", \"rarely\"\n",
    "}\n",
    "\n",
    "NEGATION_WHITELIST = (\n",
    "    EXPLICIT_NEG |\n",
    "    AUX_NEG |\n",
    "    IMPLICIT_NEG_VERBS |\n",
    "    WEAK_NEG_ADVERBS\n",
    ")\n",
    "\n",
    "def dynamic_stopwords(token_lists, min_freq=500):\n",
    "    freq = Counter()\n",
    "    for toks in token_lists:\n",
    "        freq.update(toks)\n",
    "\n",
    "    return {\n",
    "        w for w, c in freq.items()\n",
    "        if c >= min_freq\n",
    "        and w not in STOPWORDS\n",
    "        and w not in NEGATION_WHITELIST\n",
    "    }\n",
    "\n",
    "def tokenize(text, dynamic_sw=None):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = set()\n",
    "\n",
    "    for tok in doc:\n",
    "        if tok.is_punct or tok.is_space:\n",
    "            continue\n",
    "\n",
    "        lemma = tok.lemma_\n",
    "\n",
    "        if lemma in STOPWORDS:\n",
    "            continue\n",
    "\n",
    "        if dynamic_sw and lemma in dynamic_sw:\n",
    "            continue\n",
    "\n",
    "        if TOKEN_RE.fullmatch(lemma):\n",
    "            tokens.add(lemma)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def negation_score(tokens):\n",
    "    score = 0\n",
    "    if tokens & EXPLICIT_NEG:\n",
    "        score += 2\n",
    "    if tokens & AUX_NEG:\n",
    "        score += 2\n",
    "    if tokens & IMPLICIT_NEG_VERBS:\n",
    "        score += 1\n",
    "    if tokens & WEAK_NEG_ADVERBS:\n",
    "        score += 0.5\n",
    "    return score\n",
    "\n",
    "\n",
    "def label_pair(\n",
    "    claim,\n",
    "    evidence,\n",
    "    c_emb,\n",
    "    e_emb,\n",
    "    global_label,\n",
    "    character,\n",
    "    dynamic_sw\n",
    "):\n",
    "    # tokenize with dynamic stopwords\n",
    "    c_tok = tokenize(claim, dynamic_sw)\n",
    "    e_tok = tokenize(evidence, dynamic_sw)\n",
    "\n",
    "    # hard character grounding\n",
    "    if character.lower() not in evidence.lower():\n",
    "        return \"NEUTRAL\"\n",
    "\n",
    "    # semantic similarity (embeddings are assumed normalized)\n",
    "    sim = float(np.dot(c_emb, e_emb))\n",
    "\n",
    "    # negation polarity\n",
    "    c_neg = negation_score(c_tok)\n",
    "    e_neg = negation_score(e_tok)\n",
    "\n",
    "    # lexical signal (secondary)\n",
    "    overlap = len(c_tok & e_tok)\n",
    "\n",
    "    # ---------------- SUPPORT ----------------\n",
    "    if global_label == \"consistent\":\n",
    "        if sim >= 0.70 and abs(c_neg - e_neg) < 1:\n",
    "            return \"SUPPORT\"\n",
    "\n",
    "        if sim >= 0.60 and overlap >= 2:\n",
    "            return \"SUPPORT\"\n",
    "\n",
    "        return \"NEUTRAL\"\n",
    "\n",
    "    # ---------------- CONTRADICTION ----------------\n",
    "    if global_label == \"contradict\":\n",
    "        if sim >= 0.65 and abs(c_neg - e_neg) >= 2:\n",
    "            return \"CONTRADICT\"\n",
    "\n",
    "        if sim >= 0.70 and e_neg > 0 and c_neg == 0:\n",
    "            return \"CONTRADICT\"\n",
    "\n",
    "        return \"NEUTRAL\"\n",
    "\n",
    "    return \"NEUTRAL\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cafbd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution: Counter({'NEUTRAL': 26, 'SUPPORT': 7, 'CONTRADICT': 6})\n"
     ]
    }
   ],
   "source": [
    "pairs = []\n",
    "label_counts = Counter()\n",
    "\n",
    "SIM_FLOOR = 0.55        # hard semantic filter\n",
    "MAX_EVIDENCE = 2        # per claim\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Build dynamic stopwords ONCE\n",
    "# -------------------------------------------------\n",
    "all_texts = []\n",
    "\n",
    "with open(IN_PATH, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        ex = json.loads(line)\n",
    "        all_texts.append(ex[\"claim_text\"])\n",
    "        for ev in ex[\"evidence\"]:\n",
    "            all_texts.append(ev[\"text\"])\n",
    "\n",
    "token_lists = [tokenize(t) for t in all_texts]\n",
    "DYNAMIC_STOPWORDS = dynamic_stopwords(token_lists, min_freq=500)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Generate NLI pairs (FILTERED)\n",
    "# -------------------------------------------------\n",
    "with open(IN_PATH, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        ex = json.loads(line)\n",
    "\n",
    "        # encode claim once\n",
    "        c_emb = embedder.encode(\n",
    "            ex[\"claim_text\"],\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True\n",
    "        )\n",
    "\n",
    "        # sort evidence by similarity (descending)\n",
    "        evidence_sorted = sorted(\n",
    "            ex[\"evidence\"],\n",
    "            key=lambda x: x.get(\"similarity\", 0.0),\n",
    "            reverse=True\n",
    "        )\n",
    "\n",
    "        kept = 0\n",
    "        for ev in evidence_sorted:\n",
    "            if kept >= MAX_EVIDENCE:\n",
    "                break\n",
    "\n",
    "            # semantic floor\n",
    "            if ev.get(\"similarity\", 0.0) < SIM_FLOOR:\n",
    "                continue\n",
    "\n",
    "            # encode evidence\n",
    "            e_emb = embedder.encode(\n",
    "                ev[\"text\"],\n",
    "                convert_to_numpy=True,\n",
    "                normalize_embeddings=True\n",
    "            )\n",
    "\n",
    "            lbl = label_pair(\n",
    "                claim=ex[\"claim_text\"],\n",
    "                evidence=ev[\"text\"],\n",
    "                c_emb=c_emb,\n",
    "                e_emb=e_emb,\n",
    "                global_label=ex[\"label\"],\n",
    "                character=ex[\"character\"],\n",
    "                dynamic_sw=DYNAMIC_STOPWORDS\n",
    "            )\n",
    "\n",
    "            # drop weak NEUTRALs\n",
    "            if lbl == \"NEUTRAL\" and ev[\"similarity\"] < 0.60:\n",
    "                continue\n",
    "\n",
    "            pairs.append({\n",
    "                \"claim_id\": ex[\"claim_id\"],\n",
    "                \"claim\": ex[\"claim_text\"],\n",
    "                \"evidence\": ev[\"text\"],\n",
    "                \"label\": lbl\n",
    "            })\n",
    "\n",
    "            label_counts[lbl] += 1\n",
    "            kept += 1\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Save\n",
    "# -------------------------------------------------\n",
    "print(\"Label distribution:\", label_counts)\n",
    "\n",
    "with open(f\"{OUT_DIR}/nli_pairs.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for p in pairs:\n",
    "        f.write(json.dumps(p, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b80f3877",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_claim = defaultdict(list)\n",
    "for p in pairs:\n",
    "    by_claim[p[\"claim_id\"]].append(p)\n",
    "\n",
    "claim_ids = list(by_claim.keys())\n",
    "random.shuffle(claim_ids)\n",
    "\n",
    "# ----------\n",
    "\n",
    "n = len(claim_ids)\n",
    "\n",
    "train_ids = set(claim_ids[: int(0.8 * n)])\n",
    "dev_ids   = set(claim_ids[int(0.8 * n): int(0.9 * n)])\n",
    "test_ids  = set(claim_ids[int(0.9 * n):])\n",
    "\n",
    "# ------------\n",
    "\n",
    "train, dev, test = [], [], []\n",
    "\n",
    "for cid, items in by_claim.items():\n",
    "    if cid in train_ids:\n",
    "        train.extend(items)\n",
    "    elif cid in dev_ids:\n",
    "        dev.extend(items)\n",
    "    else:\n",
    "        test.extend(items)\n",
    "\n",
    "# ------------\n",
    "\n",
    "def dump(name, data):\n",
    "    with open(f\"{OUT_DIR}/{name}.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for x in data:\n",
    "            f.write(json.dumps(x, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "dump(\"nli_train\", train)\n",
    "dump(\"nli_dev\", dev)\n",
    "dump(\"nli_test\", test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f33aaf",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd51c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "LABEL_MAP = {\"SUPPORT\": 0, \"NEUTRAL\": 1, \"CONTRADICT\": 2}\n",
    "\n",
    "class NLIDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer, max_len=256):\n",
    "        self.data = [json.loads(l) for l in open(path, encoding=\"utf-8\")]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ex = self.data[idx]\n",
    "\n",
    "        enc = self.tokenizer(\n",
    "            ex[\"evidence\"],\n",
    "            ex[\"claim\"],\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(LABEL_MAP[ex[\"label\"]], dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386f4550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f95bf800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\tahmi\\AppData\\Local\\Temp\\ipykernel_28740\\1878110439.py:40: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n",
      "c:\\Users\\tahmi\\Documents\\Work\\HACKATHONS\\iitk_26\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 02:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.048380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.856266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.675870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Best NLI model saved to: models2/nli/best_model\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "OUTPUT_DIR = \"models2/nli\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    use_fast=True\n",
    ")\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3\n",
    ")\n",
    "\n",
    "\n",
    "train_ds = NLIDataset(\"data2/nli/nli_train.jsonl\", tokenizer)\n",
    "dev_ds   = NLIDataset(\"data2/nli/nli_dev.jsonl\", tokenizer)\n",
    "\n",
    "\n",
    "collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    save_only_model=True,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=dev_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "BEST_DIR = f\"{OUTPUT_DIR}/best_model\"\n",
    "trainer.save_model(BEST_DIR)\n",
    "tokenizer.save_pretrained(BEST_DIR)\n",
    "\n",
    "print(f\"==> Best NLI model saved to: {BEST_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a354d117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(self, output_dir: Optional[str] = None, overwrite_output_dir: bool = False, do_train: bool = False, do_eval: bool = False, do_predict: bool = False, eval_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'no', prediction_loss_only: bool = False, per_device_train_batch_size: int = 8, per_device_eval_batch_size: int = 8, per_gpu_train_batch_size: Optional[int] = None, per_gpu_eval_batch_size: Optional[int] = None, gradient_accumulation_steps: int = 1, eval_accumulation_steps: Optional[int] = None, eval_delay: float = 0, torch_empty_cache_steps: Optional[int] = None, learning_rate: float = 5e-05, weight_decay: float = 0.0, adam_beta1: float = 0.9, adam_beta2: float = 0.999, adam_epsilon: float = 1e-08, max_grad_norm: float = 1.0, num_train_epochs: float = 3.0, max_steps: int = -1, lr_scheduler_type: Union[transformers.trainer_utils.SchedulerType, str] = 'linear', lr_scheduler_kwargs: Union[dict[str, Any], str] = <factory>, warmup_ratio: float = 0.0, warmup_steps: int = 0, log_level: str = 'passive', log_level_replica: str = 'warning', log_on_each_node: bool = True, logging_dir: Optional[str] = None, logging_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'steps', logging_first_step: bool = False, logging_steps: float = 500, logging_nan_inf_filter: bool = True, save_strategy: Union[transformers.trainer_utils.SaveStrategy, str] = 'steps', save_steps: float = 500, save_total_limit: Optional[int] = None, save_safetensors: bool = True, save_on_each_node: bool = False, save_only_model: bool = False, restore_callback_states_from_checkpoint: bool = False, no_cuda: bool = False, use_cpu: bool = False, use_mps_device: bool = False, seed: int = 42, data_seed: Optional[int] = None, jit_mode_eval: bool = False, bf16: bool = False, fp16: bool = False, fp16_opt_level: str = 'O1', half_precision_backend: str = 'auto', bf16_full_eval: bool = False, fp16_full_eval: bool = False, tf32: Optional[bool] = None, local_rank: int = -1, ddp_backend: Optional[str] = None, tpu_num_cores: Optional[int] = None, tpu_metrics_debug: bool = False, debug: Union[str, list[transformers.debug_utils.DebugOption]] = '', dataloader_drop_last: bool = False, eval_steps: Optional[float] = None, dataloader_num_workers: int = 0, dataloader_prefetch_factor: Optional[int] = None, past_index: int = -1, run_name: Optional[str] = None, disable_tqdm: Optional[bool] = None, remove_unused_columns: bool = True, label_names: Optional[list[str]] = None, load_best_model_at_end: bool = False, metric_for_best_model: Optional[str] = None, greater_is_better: Optional[bool] = None, ignore_data_skip: bool = False, fsdp: Union[list[transformers.trainer_utils.FSDPOption], str, NoneType] = None, fsdp_min_num_params: int = 0, fsdp_config: Union[dict[str, Any], str, NoneType] = None, fsdp_transformer_layer_cls_to_wrap: Optional[str] = None, accelerator_config: Union[dict, str, NoneType] = None, parallelism_config: Optional[Any] = None, deepspeed: Union[dict, str, NoneType] = None, label_smoothing_factor: float = 0.0, optim: Union[transformers.training_args.OptimizerNames, str] = 'adamw_torch_fused', optim_args: Optional[str] = None, adafactor: bool = False, group_by_length: bool = False, length_column_name: str = 'length', report_to: Union[NoneType, str, list[str]] = None, project: str = 'huggingface', trackio_space_id: Optional[str] = 'trackio', ddp_find_unused_parameters: Optional[bool] = None, ddp_bucket_cap_mb: Optional[int] = None, ddp_broadcast_buffers: Optional[bool] = None, dataloader_pin_memory: bool = True, dataloader_persistent_workers: bool = False, skip_memory_metrics: bool = True, use_legacy_prediction_loop: bool = False, push_to_hub: bool = False, resume_from_checkpoint: Optional[str] = None, hub_model_id: Optional[str] = None, hub_strategy: Union[transformers.trainer_utils.HubStrategy, str] = 'every_save', hub_token: Optional[str] = None, hub_private_repo: Optional[bool] = None, hub_always_push: bool = False, hub_revision: Optional[str] = None, gradient_checkpointing: bool = False, gradient_checkpointing_kwargs: Union[dict[str, Any], str, NoneType] = None, include_inputs_for_metrics: bool = False, include_for_metrics: list[str] = <factory>, eval_do_concat_batches: bool = True, fp16_backend: str = 'auto', push_to_hub_model_id: Optional[str] = None, push_to_hub_organization: Optional[str] = None, push_to_hub_token: Optional[str] = None, mp_parameters: str = '', auto_find_batch_size: bool = False, full_determinism: bool = False, torchdynamo: Optional[str] = None, ray_scope: Optional[str] = 'last', ddp_timeout: int = 1800, torch_compile: bool = False, torch_compile_backend: Optional[str] = None, torch_compile_mode: Optional[str] = None, include_tokens_per_second: bool = False, include_num_input_tokens_seen: Union[str, bool] = False, neftune_noise_alpha: Optional[float] = None, optim_target_modules: Union[NoneType, str, list[str]] = None, batch_eval_metrics: bool = False, eval_on_start: bool = False, use_liger_kernel: bool = False, liger_kernel_config: Optional[dict[str, bool]] = None, eval_use_gather_object: bool = False, average_tokens_across_devices: bool = True) -> None\n"
     ]
    }
   ],
   "source": [
    "# import inspect\n",
    "# from transformers import TrainingArguments\n",
    "\n",
    "# print(inspect.signature(TrainingArguments.__init__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e1b67f",
   "metadata": {},
   "source": [
    "# Temporal and Casual Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0a8dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"models2/nli/best_model\"\n",
    "CLAIM_EVIDENCE = \"data2/retrieval/claim_evidence.jsonl\"\n",
    "CLAIMS_PATH = \"data2/decomposed/claims.jsonl\"\n",
    "OUT_FINAL = \"data2/final_predictions.jsonl\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, use_fast=False)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "LABELS = [\"SUPPORT\", \"NEUTRAL\", \"CONTRADICT\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67ff07ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "nli_by_claim = defaultdict(list)\n",
    "\n",
    "with open(CLAIM_EVIDENCE, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        ex = json.loads(line)\n",
    "\n",
    "        for ev in ex[\"evidence\"]:\n",
    "            inputs = tokenizer(\n",
    "                ev[\"text\"],          # premise\n",
    "                ex[\"claim_text\"],    # hypothesis\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=256\n",
    "            )\n",
    "\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(**inputs).logits\n",
    "                probs = F.softmax(logits, dim=-1)[0].cpu().tolist()\n",
    "\n",
    "            max_p = max(probs)\n",
    "\n",
    "            # Neurtral filter\n",
    "            if max_p < 0.6:\n",
    "                continue\n",
    "\n",
    "            nli_by_claim[ex[\"claim_id\"]].append({\n",
    "                \"chunk_id\": ev[\"chunk_id\"],\n",
    "                \"probs\": dict(zip(LABELS, probs)),\n",
    "                \"confidence\": max_p,\n",
    "                \"text\": ev[\"text\"],\n",
    "                \"row_id\": ex[\"row_id\"],\n",
    "                \"character\": ex[\"character\"]\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e46f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLI_OUT = \"data2/nli/nli_predictions.jsonl\"\n",
    "\n",
    "with open(NLI_OUT, \"w\", encoding=\"utf-8\") as fout:\n",
    "    for claim_id, preds in nli_by_claim.items():\n",
    "        for p in preds:\n",
    "            fout.write(json.dumps({\n",
    "                \"claim_id\": claim_id,\n",
    "                **p\n",
    "            }) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "950f3fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORTANT_VERBS = {\n",
    "    \"read\", \"write\", \"learn\", \"teach\", \"know\",\n",
    "    \"escape\", \"die\", \"kill\", \"marry\",\n",
    "    \"imprison\", \"free\", \"fight\", \"travel\"\n",
    "}\n",
    "\n",
    "STOP_SUBJECTS = {\"he\", \"she\", \"they\", \"it\", \"who\", \"which\"}\n",
    "\n",
    "def extract_events(text, time_anchor):\n",
    "    doc = nlp(text)\n",
    "    events = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        for tok in sent:\n",
    "            if tok.pos_ == \"VERB\":\n",
    "                lemma = tok.lemma_.lower()\n",
    "\n",
    "                if lemma not in IMPORTANT_VERBS:\n",
    "                    continue\n",
    "\n",
    "                subj = next(\n",
    "                    (c.text for c in tok.children if c.dep_ == \"nsubj\"),\n",
    "                    None\n",
    "                )\n",
    "\n",
    "                if not subj:\n",
    "                    continue\n",
    "\n",
    "                subj = subj.lower()\n",
    "\n",
    "                if subj in STOP_SUBJECTS:\n",
    "                    continue\n",
    "\n",
    "                events.append({\n",
    "                    \"character\": subj,\n",
    "                    \"event\": lemma,\n",
    "                    \"time\": time_anchor\n",
    "                })\n",
    "\n",
    "    return events\n",
    "\n",
    "\n",
    "def claim_to_constraints(claim, character):\n",
    "    \"\"\"\n",
    "    Convert a natural-language claim into\n",
    "    temporal / causal constraints.\n",
    "\n",
    "    Returns:\n",
    "        dict with keys:\n",
    "        - character\n",
    "        - forbidden_events\n",
    "        - allowed_after\n",
    "        - strength   (soft | hard)\n",
    "    \"\"\"\n",
    "    c = claim.lower()\n",
    "    character = character.lower()\n",
    "\n",
    "    # -----------------------------\n",
    "    # ABILITY / KNOWLEDGE CLAIMS\n",
    "    # -----------------------------\n",
    "    if any(k in c for k in [\"illiterate\", \"could not read\", \"unable to read\"]):\n",
    "        return {\n",
    "            \"character\": character,\n",
    "            \"forbidden_events\": [\"read\", \"write\"],\n",
    "            \"allowed_after\": [\"learn\", \"teach\", \"study\"],\n",
    "            \"strength\": \"soft\"\n",
    "        }\n",
    "\n",
    "    if any(k in c for k in [\"educated\", \"well-read\", \"scholar\"]):\n",
    "        return {\n",
    "            \"character\": character,\n",
    "            \"forbidden_events\": [],\n",
    "            \"allowed_after\": [\"learn\", \"teach\", \"study\"],\n",
    "            \"strength\": \"soft\"\n",
    "        }\n",
    "\n",
    "    # -----------------------------\n",
    "    # MOVEMENT / ESCAPE CLAIMS\n",
    "    # -----------------------------\n",
    "    if any(k in c for k in [\"never escaped\", \"did not escape\", \"failed to escape\"]):\n",
    "        return {\n",
    "            \"character\": character,\n",
    "            \"forbidden_events\": [\"escape\", \"travel\"],\n",
    "            \"allowed_after\": [],\n",
    "            \"strength\": \"hard\"\n",
    "        }\n",
    "\n",
    "    if any(k in c for k in [\"escaped\", \"fled\", \"broke free\"]):\n",
    "        return {\n",
    "            \"character\": character,\n",
    "            \"forbidden_events\": [],\n",
    "            \"allowed_after\": [\"escape\"],\n",
    "            \"strength\": \"soft\"\n",
    "        }\n",
    "\n",
    "    # -----------------------------\n",
    "    # LIFE / DEATH CLAIMS\n",
    "    # -----------------------------\n",
    "    if any(k in c for k in [\"died\", \"was killed\", \"perished\"]):\n",
    "        return {\n",
    "            \"character\": character,\n",
    "            \"forbidden_events\": [\n",
    "                \"travel\", \"fight\", \"marry\", \"teach\", \"escape\"\n",
    "            ],\n",
    "            \"allowed_after\": [],\n",
    "            \"strength\": \"hard\"\n",
    "        }\n",
    "\n",
    "    # -----------------------------\n",
    "    # RELATIONSHIP CLAIMS\n",
    "    # -----------------------------\n",
    "    if any(k in c for k in [\"never married\", \"remained single\"]):\n",
    "        return {\n",
    "            \"character\": character,\n",
    "            \"forbidden_events\": [\"marry\"],\n",
    "            \"allowed_after\": [],\n",
    "            \"strength\": \"hard\"\n",
    "        }\n",
    "\n",
    "    # -----------------------------\n",
    "    # DEFAULT\n",
    "    # -----------------------------\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "800edc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_violation_score(claim_struct, timeline):\n",
    "    \"\"\"\n",
    "    Returns a soft temporal violation penalty in [0, 1].\n",
    "\n",
    "    - Scales with number of violations\n",
    "    - Normalized by timeline size\n",
    "    - Respects hard vs soft constraints\n",
    "    - Stronger penalty for earlier violations\n",
    "    \"\"\"\n",
    "\n",
    "    char = claim_struct[\"character\"]\n",
    "    forbidden = claim_struct.get(\"forbidden_events\", [])\n",
    "    allowed_after = claim_struct.get(\"allowed_after\", [])\n",
    "    strength = claim_struct.get(\"strength\", \"soft\")\n",
    "\n",
    "    events = timeline.get(char, [])\n",
    "    if not events:\n",
    "        return 0.0\n",
    "\n",
    "    # sort by time (early events matter more)\n",
    "    events = sorted(events, key=lambda x: x[\"time\"])\n",
    "\n",
    "    violation_score = 0.0\n",
    "    total_weight = 0.0\n",
    "\n",
    "    for idx, e in enumerate(events):\n",
    "        if e[\"event\"] not in forbidden:\n",
    "            continue\n",
    "\n",
    "        # earlier violations are more severe\n",
    "        time_weight = 1.0 - (idx / len(events))\n",
    "\n",
    "        explained = any(\n",
    "            ev[\"event\"] in allowed_after and ev[\"time\"] < e[\"time\"]\n",
    "            for ev in events\n",
    "        )\n",
    "\n",
    "        if not explained:\n",
    "            violation_score += time_weight\n",
    "            total_weight += time_weight\n",
    "\n",
    "    if total_weight == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # normalize to [0, 1]\n",
    "    penalty = violation_score / total_weight\n",
    "\n",
    "    # hard constraints are more serious\n",
    "    if strength == \"hard\":\n",
    "        penalty *= 1.0\n",
    "    else:\n",
    "        penalty *= 0.5\n",
    "\n",
    "    return min(penalty, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30a2da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_row(decisions):\n",
    "    \"\"\"\n",
    "    Balanced row-level aggregation.\n",
    "    Consistency must be supported.\n",
    "    Contradiction must be explicit.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(decisions)\n",
    "\n",
    "    c_contra = decisions.count(\"CONTRADICT\")\n",
    "    c_supp   = decisions.count(\"SUPPORT\")\n",
    "    c_neu    = decisions.count(\"NEUTRAL\")\n",
    "\n",
    "    # explicit contradiction dominates\n",
    "    if c_contra >= 1:\n",
    "        return \"contradict\"\n",
    "\n",
    "    # support dominates\n",
    "    if c_supp >= max(2, n // 2 + 1):\n",
    "        return \"consistent\"\n",
    "\n",
    "    # Ambiguous cases: lean to consistent\n",
    "    # (neutral  contradiction)\n",
    "    return \"consistent\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def decide_claim(nli_preds, claim_struct, timeline):\n",
    "    \"\"\"\n",
    "    Calibrated claim-level decision.\n",
    "    Designed for weak NLI + literary text.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(nli_preds)\n",
    "\n",
    "    mean_contra = sum(p[\"probs\"][\"CONTRADICT\"] for p in nli_preds) / n\n",
    "    mean_supp   = sum(p[\"probs\"][\"SUPPORT\"]    for p in nli_preds) / n\n",
    "    mean_neu    = sum(p[\"probs\"][\"NEUTRAL\"]    for p in nli_preds) / n\n",
    "\n",
    "    max_contra = max(p[\"probs\"][\"CONTRADICT\"] for p in nli_preds)\n",
    "    max_supp   = max(p[\"probs\"][\"SUPPORT\"]    for p in nli_preds)\n",
    "\n",
    "    strong_contra = sum(p[\"probs\"][\"CONTRADICT\"] > 0.6 for p in nli_preds)\n",
    "    strong_supp   = sum(p[\"probs\"][\"SUPPORT\"]    > 0.6 for p in nli_preds)\n",
    "\n",
    "    # ---- base semantic score ----\n",
    "    score = (\n",
    "        0.35 * (mean_contra - mean_supp) +\n",
    "        0.35 * (max_contra  - max_supp) +\n",
    "        0.30 * (strong_contra - strong_supp)\n",
    "    )\n",
    "\n",
    "    # ---- softer neutral dampening ----\n",
    "    score *= (1.0 - 0.7 * mean_neu)\n",
    "\n",
    "    # ---- temporal reasoning ----\n",
    "    if claim_struct:\n",
    "        temporal_penalty = temporal_violation_score(claim_struct, timeline)\n",
    "\n",
    "        # temporal logic can tip the balance\n",
    "        score += 0.3 * temporal_penalty\n",
    "\n",
    "    # ---- decision thresholds (ASYMMETRIC) ----\n",
    "    if score > 0.05:\n",
    "        return \"CONTRADICT\"\n",
    "\n",
    "    if score < -0.10:\n",
    "        return \"SUPPORT\"\n",
    "\n",
    "    return \"NEUTRAL\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4e7c49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading NLI predictions: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded NLI predictions for 0 claims\n",
      " Loading cached timeline...\n",
      " Loaded timelines for 107 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating claims: 204it [00:00, 184763.12it/s]\n",
      "Writing final predictions: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Final predictions written to: data2/final_predictions.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================================================\n",
    "# PATHS\n",
    "# ============================================================\n",
    "\n",
    "CLAIM_EVIDENCE = \"data2/retrieval/claim_evidence.jsonl\"\n",
    "CLAIMS_PATH = \"data2/decomposed/claims.jsonl\"\n",
    "NLI_PRED_PATH = \"data2/nli/nli_predictions.jsonl\"\n",
    "OUT_FINAL = \"data2/final_predictions.jsonl\"\n",
    "TIMELINE_CACHE = \"data/cache/timeline.json\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. LOAD NLI PREDICTIONS\n",
    "# ============================================================\n",
    "\n",
    "nli_by_claim = defaultdict(list)\n",
    "\n",
    "with open(NLI_PRED_PATH, encoding=\"utf-8\") as f:\n",
    "    for line in tqdm(f, desc=\"Loading NLI predictions\"):\n",
    "        p = json.loads(line)\n",
    "        nli_by_claim[p[\"claim_id\"]].append(p)\n",
    "\n",
    "print(f\" Loaded NLI predictions for {len(nli_by_claim)} claims\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. BUILD EVENT TIMELINES\n",
    "# ============================================================\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "timeline = defaultdict(list)\n",
    "\n",
    "def normalize_name(name):\n",
    "    return name.lower().strip()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load cached timeline if available\n",
    "# ------------------------------------------------------------\n",
    "if os.path.exists(TIMELINE_CACHE):\n",
    "    print(\" Loading cached timeline...\")\n",
    "\n",
    "    with open(TIMELINE_CACHE, encoding=\"utf-8\") as f:\n",
    "        timeline_data = json.load(f)\n",
    "\n",
    "    for char, events in timeline_data.items():\n",
    "        timeline[char].extend(events)\n",
    "\n",
    "    print(f\" Loaded timelines for {len(timeline)} characters\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Otherwise, build timeline and cache it\n",
    "# ------------------------------------------------------------\n",
    "else:\n",
    "    print(\" Building timeline from evidence...\")\n",
    "\n",
    "    with open(CLAIM_EVIDENCE, encoding=\"utf-8\") as f:\n",
    "        for line in tqdm(f, desc=\"Building timelines\"):\n",
    "            ex = json.loads(line)\n",
    "            time_anchor = ex[\"row_id\"]  # coarse temporal ordering\n",
    "\n",
    "            for ev in ex[\"evidence\"]:\n",
    "                events = extract_events(ev[\"text\"], time_anchor)\n",
    "\n",
    "                for e in events:\n",
    "                    e[\"character\"] = normalize_name(e[\"character\"])\n",
    "                    timeline[e[\"character\"]].append(e)\n",
    "\n",
    "    # Save as a normal dict (JSON-safe)\n",
    "    with open(TIMELINE_CACHE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(dict(timeline), f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\" Built & cached timelines for {len(timeline)} characters\")\n",
    "    \n",
    "    \n",
    "# ============================================================\n",
    "# 3. CLAIM-LEVEL AGGREGATION\n",
    "# ============================================================\n",
    "\n",
    "row_votes = defaultdict(list)\n",
    "\n",
    "with open(CLAIMS_PATH, encoding=\"utf-8\") as f:\n",
    "    for line in tqdm(f, desc=\"Aggregating claims\"):\n",
    "        c = json.loads(line)\n",
    "\n",
    "        claim_id = c[\"claim_id\"]\n",
    "        row_id = c[\"row_id\"]\n",
    "        character = normalize_name(c[\"character\"])\n",
    "\n",
    "        preds = nli_by_claim.get(claim_id)\n",
    "        if not preds:\n",
    "            continue\n",
    "\n",
    "        struct = claim_to_constraints(c[\"claim_text\"], character)\n",
    "        decision = decide_claim(preds, struct, timeline)\n",
    "\n",
    "        row_votes[row_id].append(decision)\n",
    "\n",
    "# ============================================================\n",
    "# 4. ROW-LEVEL FINAL DECISION (UPDATED)\n",
    "# ============================================================\n",
    "\n",
    "with open(OUT_FINAL, \"w\", encoding=\"utf-8\") as f:\n",
    "    for row_id, decisions in tqdm(row_votes.items(), desc=\"Writing final predictions\"):\n",
    "        final = decide_row(decisions)\n",
    "\n",
    "        f.write(json.dumps({\n",
    "            \"row_id\": row_id,\n",
    "            \"prediction\": final,\n",
    "            \"claim_decisions\": decisions\n",
    "        }) + \"\\n\")\n",
    "\n",
    "print(f\"\\n==> Final predictions written to: {OUT_FINAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c847552a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Claim-level distribution:\n",
      "Counter()\n",
      "\n",
      "Row-level distribution:\n",
      "Counter()\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"\\nClaim-level distribution:\")\n",
    "print(Counter(d for decisions in row_votes.values() for d in decisions))\n",
    "\n",
    "print(\"\\nRow-level distribution:\")\n",
    "print(Counter(decide_row(decisions) for decisions in row_votes.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4af092a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 80 samples\n",
      "\n",
      " Improved Evaluation Metrics\n",
      "\n",
      "Accuracy           : 0.6125\n",
      "Balanced Accuracy  : 0.5548\n",
      "Macro Precision    : 0.5635\n",
      "Macro Recall       : 0.5548\n",
      "Macro F1-score     : 0.5539\n",
      "MCC                : 0.1179\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10 19]\n",
      " [12 39]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "TRAIN_CSV = \"data/raw/train.csv\"\n",
    "PRED_PATH = \"data/final_predictions.jsonl\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "# Map labels: consistent  1, contradict  0\n",
    "gold = {\n",
    "    int(row[\"id\"]): 1 if row[\"label\"] == \"consistent\" else 0\n",
    "    for _, row in df.iterrows()\n",
    "}\n",
    "\n",
    "\n",
    "pred = {}\n",
    "\n",
    "with open(PRED_PATH, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        ex = json.loads(line)\n",
    "        pred_label = 1 if ex[\"prediction\"] == \"consistent\" else 0\n",
    "        pred[int(ex[\"row_id\"])] = pred_label\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for row_id, y in gold.items():\n",
    "    if row_id in pred:\n",
    "        y_true.append(y)\n",
    "        y_pred.append(pred[row_id])\n",
    "\n",
    "print(f\"Evaluated on {len(y_true)} samples\")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    matthews_corrcoef,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n Improved Evaluation Metrics\\n\")\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "# Macro F1\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    average=\"macro\"\n",
    ")\n",
    "\n",
    "print(f\"Accuracy           : {accuracy:.4f}\")\n",
    "print(f\"Balanced Accuracy  : {balanced_acc:.4f}\")\n",
    "print(f\"Macro Precision    : {precision:.4f}\")\n",
    "print(f\"Macro Recall       : {recall:.4f}\")\n",
    "print(f\"Macro F1-score     : {f1:.4f}\")\n",
    "print(f\"MCC                : {mcc:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba323750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
